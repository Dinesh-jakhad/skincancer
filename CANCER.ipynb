{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd2738e-f001-4959-923b-ef7adeb08ff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17636\\2287607586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m \u001b[1;31m# used for converting labels to one-hot-encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(42)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "skin_df = pd.read_csv('b:/HAM10000_metadata.csv')\n",
    "\n",
    "SIZE=32\n",
    "\n",
    "# label encoding to numeric values from text\n",
    "le = LabelEncoder()\n",
    "le.fit(skin_df['dx'])\n",
    "LabelEncoder()\n",
    "print(list(le.classes_))\n",
    " \n",
    "skin_df['label'] = le.transform(skin_df[\"dx\"]) \n",
    "print(skin_df.sample(10))\n",
    "\n",
    "\n",
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "skin_df['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Cell Type');\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "skin_df['sex'].value_counts().plot(kind='bar', ax=ax2)\n",
    "ax2.set_ylabel('Count', size=15)\n",
    "ax2.set_title('Sex');\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "skin_df['localization'].value_counts().plot(kind='bar')\n",
    "ax3.set_ylabel('Count',size=12)\n",
    "ax3.set_title('Localization')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "sample_age = skin_df[pd.notnull(skin_df['age'])]\n",
    "sns.distplot(sample_age['age'], fit=stats.norm, color='red');\n",
    "ax4.set_title('Age')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribution of data into various classes \n",
    "from sklearn.utils import resample\n",
    "print(skin_df['label'].value_counts())\n",
    "\n",
    "#Balance data.\n",
    "# Many ways to balance data... you can also try assigning weights during model.fit\n",
    "#Separate each classes, resample, and combine back into single dataframe\n",
    "\n",
    "df_0 = skin_df[skin_df['label'] == 0]\n",
    "df_1 = skin_df[skin_df['label'] == 1]\n",
    "df_2 = skin_df[skin_df['label'] == 2]\n",
    "df_3 = skin_df[skin_df['label'] == 3]\n",
    "df_4 = skin_df[skin_df['label'] == 4]\n",
    "df_5 = skin_df[skin_df['label'] == 5]\n",
    "df_6 = skin_df[skin_df['label'] == 6]\n",
    "\n",
    "n_samples=500 \n",
    "df_0_balanced = resample(df_0, replace=True, n_samples=n_samples, random_state=42) \n",
    "df_1_balanced = resample(df_1, replace=True, n_samples=n_samples, random_state=42) \n",
    "df_2_balanced = resample(df_2, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_3_balanced = resample(df_3, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_4_balanced = resample(df_4, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_5_balanced = resample(df_5, replace=True, n_samples=n_samples, random_state=42)\n",
    "df_6_balanced = resample(df_6, replace=True, n_samples=n_samples, random_state=42)\n",
    "\n",
    "#Combined back to a single dataframe\n",
    "skin_df_balanced = pd.concat([df_0_balanced, df_1_balanced, \n",
    "                              df_2_balanced, df_3_balanced, \n",
    "                              df_4_balanced, df_5_balanced, df_6_balanced])\n",
    "\n",
    "#Check the distribution. All classes should be balanced now.\n",
    "print(skin_df_balanced['label'].value_counts())\n",
    "\n",
    "\n",
    "#Now time to read images based on image ID from the CSV file\n",
    "#This is the safest way to read images as it ensures the right image is read for the right ID\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join('data/HAM10000/', '*', '*.jpg'))}\n",
    "\n",
    "#Define the path and add as a new column\n",
    "skin_df_balanced['path'] = skin_df['image_id'].map(image_path.get)\n",
    "#Use the path to read images.\n",
    "skin_df_balanced['image'] = skin_df_balanced['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "\n",
    "\n",
    "n_samples = 5  # number of samples for plotting\n",
    "# Plotting\n",
    "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
    "                                         skin_df_balanced.sort_values(['dx']).groupby('dx')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(c_row['image'])\n",
    "        c_ax.axis('off')\n",
    "\n",
    "#Convert dataframe column of images into numpy array\n",
    "X = np.asarray(skin_df_balanced['image'].tolist())\n",
    "X = X/255.  # Scale values to 0-1. You can also used standardscaler or other scaling methods.\n",
    "Y=skin_df_balanced['label']  #Assign label values to Y\n",
    "Y_cat = to_categorical(Y, num_classes=7) #Convert to categorical as this is a multiclass classification problem\n",
    "#Split to training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_cat, test_size=0.25, random_state=42)\n",
    "\n",
    "#Define the model.\n",
    "#I've used autokeras to find out the best model for this problem.\n",
    "#You can also load pretrained networks such as mobilenet or VGG16\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=(SIZE, SIZE, 3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "\n",
    "\n",
    "# Train\n",
    "#You can also use generator to use augmentation during training.\n",
    "\n",
    "batch_size = 16 \n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Prediction on test data\n",
    "y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_pred_classes = np.argmax(y_pred, axis = 1) \n",
    "# Convert test data to one hot vectors\n",
    "y_true = np.argmax(y_test, axis = 1) \n",
    "\n",
    "#Print confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n",
    "\n",
    "\n",
    "#PLot fractional incorrect misclassifications\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "plt.bar(np.arange(7), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96aceb-08b2-4a13-814f-03378366394e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
